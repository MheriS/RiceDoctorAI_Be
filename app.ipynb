{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class conv_layer():\n",
    "\n",
    "    # Sebagai inisialisasi layer convolusi\n",
    "    def __init__(self, total_filters, filter_shape, lr, padding = 'no_padding', stride = 1, beta1 = 0.9, beta2 = 0.999):\n",
    "        self.filters_ws = np.random.randn(*filter_shape, total_filters) * 0.1\n",
    "        self.filter_bs = np.random.randn(total_filters) * 0.1\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.din_dw = None \n",
    "        self.din_db = None\n",
    "        self.input = None\n",
    "        self.mo = 0\n",
    "        self.acc = 0\n",
    "        self.mo_b = 0\n",
    "        self.acc_b = 0\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, input, training):\n",
    "        #print(self.filters_ws)\n",
    "        self.input = np.array(input, copy=True) # Input disimpan untuk digunakan nanti pada backward pass.\n",
    "\n",
    "\n",
    "        ############### getting output dimentions here ###############\n",
    "        \n",
    "        # Dapatkan Dimensi Input dan Filter:\n",
    "        n, input_dim_h, input_dim_w, _ = input.shape\n",
    "        filter_dim_h, filter_dim_w, _, filter_dim_n = self.filters_ws.shape\n",
    "        \n",
    "        # Hitung Dimensi Output dan Padding:\n",
    "        # Jika padding pd inputan convolusi\n",
    "        # tujuan utamanya adalah mempertahankan dimensi tinggi dan lebar gambar input tetap sama setelah operasi konvolusi.\n",
    "        if self.padding == 'keep_img_dim':\n",
    "            output_shape = n, input_dim_h, input_dim_w, filter_dim_n\n",
    "            filter_dim_h, filter_dim_w, _, _ = self.filters_ws.shape\n",
    "            p_value = (filter_dim_h - 1) // 2, (filter_dim_w - 1) // 2\n",
    "        # Jika padding pada inputan convolusi 'no_padding', dimensi output dihitung berdasarkan stride dan ukuran filter:\n",
    "        elif self.padding == 'no_padding':\n",
    "            out_dim_h = (input_dim_h - filter_dim_h) // self.stride + 1\n",
    "            out_dim_w = (input_dim_w - filter_dim_w) // self.stride + 1\n",
    "            output_shape = n, out_dim_h, out_dim_w, filter_dim_n\n",
    "            p_value = 0, 0 # (0 tinggi, 0 lebar)\n",
    "        ############### got output dimentions ###############\n",
    "\n",
    "        out_dim_n, out_dim_h, out_dim_w, out_dim_c = output_shape\n",
    "\n",
    "        input_padded = self.pad(input, p_value)\n",
    "        output = np.zeros(output_shape)\n",
    "\n",
    "        # Proses pergerakan kernel/filter\n",
    "        for i in range(out_dim_h): # vertikal (tinggi)\n",
    "            for j in range(out_dim_w): # horizontal (lebar)\n",
    "                start_pix_x = i * self.stride # sumbu-x (vertikal)\n",
    "                end_pix_x = start_pix_x + filter_dim_h\n",
    "                start_pix_y = j * self.stride # sumbu-y (horizontal)\n",
    "                end_pix_y = start_pix_y + filter_dim_w\n",
    "\n",
    "                output[:, i, j, :] = np.sum(\n",
    "                    input_padded[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :, np.newaxis] *\n",
    "                    self.filters_ws[np.newaxis, :, :, :],\n",
    "                    axis=(1, 2, 3)\n",
    "                )\n",
    "\n",
    "        #print(output)\n",
    "        return output + self.filter_bs\n",
    "\n",
    "    @staticmethod\n",
    "    def pad(array, pad):\n",
    "        return np.pad(\n",
    "            array=array, # Array input yang akan di-pad.\n",
    "            pad_width=((0, 0), (pad[0], pad[0]), (pad[1], pad[1]), (0, 0)),\n",
    "            mode='constant'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pool_layer():\n",
    "\n",
    "    def __init__(self, input_dim, stride = 2):\n",
    "        self.pool_dim = input_dim # Menyimpan dimensi pooling sebagai atribut kelas.\n",
    "        self.stride = stride # Menyimpan nilai stride sebagai atribut kelas.\n",
    "        self.input = None # Inisialisasi variabel untuk menyimpan input selama forward pass.\n",
    "        self.max_pixels = {} # Inisialisasi dictionary untuk menyimpan lokasi nilai maksimum selama forward pass untuk digunakan dalam backward pass.\n",
    "\n",
    "    def forward(self, input, training):\n",
    "        #print(input.shape)\n",
    "        self.input = np.array(input, copy=True) # Menyimpan salinan dari input untuk digunakan dalam backward pass.\n",
    "        n, input_dim_h, input_dim_w, c = input.shape # Mendapatkan bentuk dari input (batch size, height, width, channels).\n",
    "        pool_x_dim, pool_y_dim = self.pool_dim # Mendapatkan dimensi pooling (tinggi dan lebar).\n",
    "        out_dim_h = 1 + (input_dim_h - pool_x_dim) // self.stride # Menghitung dimensi tinggi output setelah pooling.\n",
    "        out_dim_w = 1 + (input_dim_w - pool_y_dim) // self.stride # Menghitung dimensi lebar output setelah pooling.\n",
    "        output = np.zeros((n, out_dim_h, out_dim_w, c)) # Menginisialisasi output dengan nol.\n",
    "\n",
    "        for i in range(out_dim_h):\n",
    "            for j in range(out_dim_w):\n",
    "                start_pix_x = i * self.stride # Menentukan koordinat awal pada sumbu x untuk area pooling.\n",
    "                end_pix_x = start_pix_x + pool_x_dim # Menentukan koordinat akhir pada sumbu x untuk area pooling.\n",
    "                start_pix_y = j * self.stride # Menentukan koordinat awal pada sumbu y untuk area pooling.\n",
    "                end_pix_y = start_pix_y + pool_y_dim # Menentukan koordinat akhir pada sumbu y untuk area pooling.\n",
    "                focus_area = input[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :] # Mengambil area fokus untuk pooling.\n",
    "                self.store_max_pixels(focus_area, (i, j)) # Menyimpan lokasi nilai maksimum dari area fokus.\n",
    "                output[:, i, j, :] = np.max(focus_area, axis=(1, 2)) # mengekstrak nilai maksimum dari setiap area pooling\n",
    "\n",
    "        #print(output)\n",
    "        return output\n",
    "\n",
    "    def store_max_pixels(self, area_pixels, i_j_location):\n",
    "        mark_max = np.zeros_like(area_pixels) # Menginisialisasi array nol dengan bentuk yang sama seperti area pixels.\n",
    "        n, h, w, c = area_pixels.shape # Mendapatkan bentuk dari area pixels.\n",
    "        area_pixels = area_pixels.reshape(n, h * w, c) # Mereset area pixels ke dalam bentuk yang mudah untuk menemukan nilai maksimum.\n",
    "        max_locations = np.argmax(area_pixels, axis=1) # Menemukan lokasi nilai maksimum dalam area pooling.\n",
    "        n_idx, c_idx = np.indices((n, c)) # Membuat indeks untuk batch dan kanal.\n",
    "        mark_max.reshape(n, h * w, c)[n_idx, max_locations, c_idx] = 1 # Menandai lokasi nilai maksimum.\n",
    "        self.max_pixels[i_j_location] = mark_max # Menyimpan tanda lokasi maksimum dalam dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reshape_layer():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_shape = () # Inisialisasi variabel instance input_shape sebagai tuple kosong. Variabel ini akan digunakan untuk menyimpan bentuk (shape) dari input yang diterima oleh layer ini.\n",
    "\n",
    "    def forward(self, input, training):\n",
    "        self.input_shape = input.shape # Menyimpan bentuk (shape) dari input ke dalam self.input_shape.\n",
    "        return np.ravel(input).reshape(input.shape[0], -1)\n",
    "        # Menggunakan np.ravel(input) untuk mengubah input menjadi array 1D (flattening).\n",
    "        # Menggunakan .reshape(input.shape[0], -1) untuk mengubah array 1D tersebut kembali menjadi 2D dengan jumlah baris sama dengan jumlah input awal (input.shape[0]) dan jumlah kolom sebanyak yang diperlukan untuk mempertahankan jumlah elemen total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ws = []\n",
    "class weights_layer():\n",
    "    def __init__(self, fan_in, fan_out, lr, beta1 = 0.9, beta2 = 0.999 , lamdaa = 0.0001):\n",
    "        self.lamdaa = lamdaa\n",
    "        self.lr = lr\n",
    "        self.ws = np.random.randn(fan_in, fan_out)/np.sqrt(fan_in)\n",
    "        self.bs = np.zeros(fan_out) #  Inisialisasi bias dengan nol\n",
    "        \n",
    "        # Inisialisasi momen dan akumulator untuk optimasi Adam.\n",
    "        self.mo = 0\n",
    "        self.acc = 0\n",
    "        self.mo_b = 0\n",
    "        self.acc_b = 0\n",
    "        \n",
    "        # Inisialisasi parameter beta1 dan beta2 untuk optimasi Adam.\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        \n",
    "    def forward(self,input, training):\n",
    "        #all_ws.append(self.ws)\n",
    "        #print(input.shape)\n",
    "        #print(np.dot(input,self.ws) + self.bs)\n",
    "        return np.dot(input,self.ws) + self.bs # Rumus Forward Propagation/Fully Connected Layer, Menghitung output dengan mengalikan input dengan bobot (self.ws) dan menambahkan bias (self.bs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input, training):\n",
    "        relu_forward = np.maximum(0,input) # setiap elemen input yang kurang dari 0 diubah menjadi 0.\n",
    "        return relu_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Log-Likelihood\n",
    "def NLL(expected_probabilities,actual_labels):\n",
    "\n",
    "    # Menentukan Probabilitas Benar\n",
    "    correct_prob = expected_probabilities[np.arange(len(expected_probabilities)),actual_labels]\n",
    "\n",
    "    p = np.exp(correct_prob) / np.sum(np.exp(expected_probabilities),axis=-1) # Implementasi softmax\n",
    "\n",
    "    loss = -1 * np.log(p) # NLL\n",
    "  \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch(CNN, X, training):\n",
    "    all_layers_outputs = []  # Membuat list kosong untuk menyimpan output dari setiap layer\n",
    "    received = X  # Menerima input awal yaitu X (input batch)\n",
    "    for layer in CNN:\n",
    "        all_layers_outputs.append(layer.forward(received, training))  # Menjalankan forward pass untuk setiap layer\n",
    "        received = all_layers_outputs[-1]  # Menyimpan output terakhir sebagai input untuk layer berikutnya\n",
    "  \n",
    "    assert len(all_layers_outputs) == len(CNN)  # Memastikan jumlah output yang dihasilkan sesuai dengan jumlah layer\n",
    "    \n",
    "    return all_layers_outputs  # Mengembalikan semua output dari setiap layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dropout_layer():\n",
    "\n",
    "    def __init__(self, keep_prob):\n",
    "        self.cutoff_prob = keep_prob  # Probabilitas untuk mempertahankan neuron\n",
    "        self.zeros_for_dropped = None  # Mask untuk neuron yang dijatuhkan\n",
    "\n",
    "    def forward(self, input, training):\n",
    "        if training:  # Jika dalam mode training\n",
    "            self.zeros_for_dropped = (np.random.rand(*input.shape) < self.cutoff_prob)  # Membuat mask dropout, dimana jika nilai input kurang dari nilai keep_prob pd dropout, neuron dijatuhkan\n",
    "            return self.drop(input, self.zeros_for_dropped)  # Terapkan dropout pada input\n",
    "        else:\n",
    "            return input  # Jika tidak dalam mode training, kembalikan input tanpa perubahan\n",
    "\n",
    "    def drop(self, input, zeros_for_dropped):\n",
    "        input *= zeros_for_dropped  # Set nilai neuron yang dijatuhkan menjadi 0\n",
    "        input /= self.cutoff_prob  # Skala ulang input untuk mempertahankan ekspektasi nilai\n",
    "        return input  # Kembalikan input yang sudah diterapkan dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "# import pygame\n",
    "# from flask import Flask, render_template, request, redirect, url_for, flash\n",
    "# from werkzeug.utils import secure_filename\n",
    "# import logging\n",
    "\n",
    "# # Initialize pygame mixer for sound\n",
    "# pygame.mixer.init()\n",
    "\n",
    "# # Create a Flask application instance\n",
    "# app = Flask(__name__, static_folder='static')\n",
    "# app.config['UPLOAD_FOLDER'] = 'static/uploads'\n",
    "# app.secret_key = 'secret_key'\n",
    "\n",
    "# # Initialize logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# current_image_name = None\n",
    "# model_notification = None\n",
    "\n",
    "# # Hardcode: Load the model from a pickle file at startup\n",
    "# MODEL_PATH = 'static/models/trained_model_manual_10000002_32_7_resize64_arsitekturbaru.pkl'\n",
    "\n",
    "# def load_model():\n",
    "#     with open(MODEL_PATH, 'rb') as file:\n",
    "#         model = pickle.load(file)\n",
    "#     return model\n",
    "\n",
    "# # Load the model at startup\n",
    "# try:\n",
    "#     CNN_loaded = load_model()\n",
    "#     model_notification = \"Model berhasil dimuat dari sistem.\"\n",
    "# except Exception as e:\n",
    "#     CNN_loaded = None\n",
    "#     model_notification = f\"Error memuat model: {str(e)}\"\n",
    "#     logging.error(model_notification)\n",
    "\n",
    "# # Function to delete all files in the upload folder\n",
    "# def delete_all_files_in_upload_folder():\n",
    "#     files = os.listdir(app.config['UPLOAD_FOLDER'])\n",
    "#     if not files:\n",
    "#         logging.info(\"Folder uploads is empty or does not exist.\")\n",
    "#     for file in files:\n",
    "#         file_path = os.path.join(app.config['UPLOAD_FOLDER'], file)\n",
    "#         if os.path.isfile(file_path):\n",
    "#             try:\n",
    "#                 os.remove(file_path)\n",
    "#                 logging.info(f\"Deleted file: {file_path}\")\n",
    "#             except Exception as e:\n",
    "#                 logging.error(f\"Error deleting file {file_path}: {e}\")\n",
    "\n",
    "# # Fungsi untuk memprediksi gambar menggunakan model CNN\n",
    "# def predict_image(model, image_path):\n",
    "#     img = cv2.imread(image_path)\n",
    "#     if img is None:\n",
    "#         raise ValueError(\"Gambar tidak dapat dibaca.\")\n",
    "    \n",
    "#     # Sesuaikan dengan ukuran input model (32x32 di sini)\n",
    "#     img = cv2.resize(img, (64, 64))\n",
    "#     img = img.astype(float) / 255.0\n",
    "#     img = np.expand_dims(img, axis=0)  # Tambahkan dimensi batch\n",
    "    \n",
    "#     # Melakukan prediksi menggunakan model\n",
    "#     # Pastikan model Anda memiliki fungsi prediksi yang sesuai dengan format ini\n",
    "#     predictions = run_batch(model, img, training=False)[-1]\n",
    "    \n",
    "#     # Terapkan softmax pada output\n",
    "#     softmax_probabilities = np.exp(predictions) / np.sum(np.exp(predictions))\n",
    "    \n",
    "#     # Tentukan ambang batas\n",
    "#     threshold = 0.7\n",
    "#     prediction = softmax_probabilities.argmax(axis=-1)[0]\n",
    "#     confidence = softmax_probabilities.max()\n",
    "\n",
    "#     # Menentukan label prediksi\n",
    "#     labels = ['blight', 'blast', 'tungro', 'healthy']\n",
    "    \n",
    "#     # Menghitung akurasi sebagai nilai kepercayaan (confidence)\n",
    "#     accuracy = confidence * 100  # Konversi ke persentase\n",
    "    \n",
    "#     # **Perbaikan: pastikan probabilities 1D**\n",
    "#     softmax_probabilities = softmax_probabilities.flatten().tolist()\n",
    "\n",
    "#     # Debug: cek output setelah flatten\n",
    "#     print(\"Softmax probabilities (flattened):\", softmax_probabilities)\n",
    "    \n",
    "#     # Mengembalikan prediksi dan akurasi\n",
    "#     if confidence < threshold:\n",
    "#         return 'bukan daun padi', accuracy, softmax_probabilities\n",
    "#     else:\n",
    "#         return labels[prediction], accuracy, softmax_probabilities\n",
    "\n",
    "# # Play sound based on prediction\n",
    "# def play_sound(prediction):\n",
    "#     sounds = {\n",
    "#         \"tungro\": \"sounds/tungro.wav\",\n",
    "#         \"blast\": \"sounds/blast.wav\",\n",
    "#         \"blight\": \"sounds/blight.wav\",\n",
    "#         \"healthy\": \"sounds/healthy.wav\",\n",
    "#         \"bukan daun padi\": \"sounds/not.mp3\"\n",
    "#     }\n",
    "#     sound_file = os.path.join('static', sounds.get(prediction.lower(), \"healthy.wav\"))\n",
    "#     if sound_file and os.path.exists(sound_file):\n",
    "#         pygame.mixer.music.load(sound_file)\n",
    "#         pygame.mixer.music.play()\n",
    "\n",
    "# # Define routes\n",
    "# @app.route('/')\n",
    "# def index():\n",
    "#     delete_all_files_in_upload_folder()\n",
    "#     global current_image_name, model_notification\n",
    "#     return render_template('index.html', \n",
    "#                            image_name=current_image_name,\n",
    "#                            model_notification=model_notification)\n",
    "\n",
    "# @app.route('/predict', methods=['POST'])\n",
    "# def predict():\n",
    "#     global CNN_loaded, current_image_name\n",
    "#     if CNN_loaded is None:\n",
    "#         flash('Model belum dimuat. Harap muat model terlebih dahulu.')\n",
    "#         return redirect(url_for('index'))\n",
    "\n",
    "#     if 'image_file' not in request.files:\n",
    "#         flash('Tidak ada file gambar yang dipilih.')\n",
    "#         return redirect(url_for('index'))\n",
    "\n",
    "#     file = request.files['image_file']\n",
    "#     if file.filename == '':\n",
    "#         flash('Tidak ada file gambar yang dipilih.')\n",
    "#         return redirect(url_for('index'))\n",
    "\n",
    "#     try:\n",
    "#         # Log file name\n",
    "#         app.logger.info(f\"Received file: {file.filename}\")\n",
    "\n",
    "#         # Save the uploaded image\n",
    "#         filename = secure_filename(file.filename)  # Pastikan secure_filename diimpor\n",
    "#         app.logger.info(f\"Secure filename: {filename}\")\n",
    "        \n",
    "#         file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "#         file.save(file_path)\n",
    "#         current_image_name = filename\n",
    "\n",
    "#         # Perform prediction\n",
    "#         prediction, accuracy, probabilities = predict_image(CNN_loaded, file_path)\n",
    "#         play_sound(prediction)\n",
    "\n",
    "#         # Return prediction results\n",
    "#         return render_template('index.html', \n",
    "#                                prediction=prediction, \n",
    "#                                accuracy=accuracy,  # Pass accuracy to the template\n",
    "#                                probabilities=probabilities,  # Tambahkan ini\n",
    "#                                labels=['blight', 'blast', 'tungro', 'healthy'],  # Label untuk menampilkan hasil\n",
    "#                                image_filename=filename,\n",
    "#                                image_name=current_image_name)\n",
    "#     except Exception as e:\n",
    "#         app.logger.error(f\"Error in prediction: {str(e)}\")\n",
    "#         flash(f\"Error: {str(e)}\")\n",
    "#         return redirect(url_for('index'))\n",
    "\n",
    "# # Run the Flask app\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "# import pygame\n",
    "# from flask import Flask, request, jsonify, redirect, url_for, flash, render_template\n",
    "# from flask_cors import CORS\n",
    "# from werkzeug.utils import secure_filename\n",
    "# import logging\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import datetime\n",
    "# from collections import defaultdict\n",
    "# import uuid\n",
    "# from calendar import month_abbr\n",
    "\n",
    "# # =========================================================================\n",
    "# # Definisi kelas dan fungsi kustom model Anda ada di file yang sama\n",
    "# # Jadi tidak perlu didefinisikan ulang di sini.\n",
    "# # Pastikan Anda menjalankan seluruh cell notebook sebelum memanggil API.\n",
    "# # =========================================================================\n",
    "\n",
    "# # Inisialisasi pygame mixer untuk suara\n",
    "# pygame.mixer.init()\n",
    "\n",
    "# # Buat instance aplikasi Flask\n",
    "# app = Flask(__name__, static_folder='static')\n",
    "# # Konfigurasi CORS yang lebih spesifik untuk mengizinkan semua\n",
    "# CORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n",
    "# app.config['UPLOAD_FOLDER'] = 'static/uploads'\n",
    "# app.secret_key = 'secret_key'\n",
    "\n",
    "# # Inisialisasi logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# current_image_name = None\n",
    "# model_notification = None\n",
    "\n",
    "# # Hardcode: Muat model dari file pickle saat startup\n",
    "# MODEL_PATH = 'static/models/trained_model_manual_10000002_32_7_resize64_arsitekturbaru.pkl'\n",
    "\n",
    "# # --- DEMO DATABASE (Data di Memori) ---\n",
    "# # Ini akan hilang setiap kali server di-restart. Gunakan database sungguhan\n",
    "# # untuk data yang persisten (misal: Firestore, SQLite).\n",
    "# dashboard_data = []\n",
    "\n",
    "# def load_model():\n",
    "#     \"\"\"Memuat model dari file pickle.\"\"\"\n",
    "#     try:\n",
    "#         with open(MODEL_PATH, 'rb') as file:\n",
    "#             model = pickle.load(file)\n",
    "#         return model\n",
    "#     except FileNotFoundError:\n",
    "#         logging.error(f\"File model tidak ditemukan di: {MODEL_PATH}\")\n",
    "#         return None\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error memuat model: {str(e)}\")\n",
    "#         return None\n",
    "\n",
    "# # Muat model saat startup\n",
    "# CNN_loaded = load_model()\n",
    "# if CNN_loaded:\n",
    "#     model_notification = \"Model berhasil dimuat dari sistem.\"\n",
    "# else:\n",
    "#     model_notification = \"Error: Model tidak dapat dimuat.\"\n",
    "\n",
    "# # Fungsi untuk menghapus semua file di folder unggahan\n",
    "# def delete_all_files_in_upload_folder():\n",
    "#     \"\"\"Menghapus semua file di folder unggahan.\"\"\"\n",
    "#     files = os.listdir(app.config['UPLOAD_FOLDER'])\n",
    "#     for file in files:\n",
    "#         file_path = os.path.join(app.config['UPLOAD_FOLDER'], file)\n",
    "#         if os.path.isfile(file_path):\n",
    "#             try:\n",
    "#                 os.remove(file_path)\n",
    "#             except Exception as e:\n",
    "#                 logging.error(f\"Error menghapus file {file_path}: {e}\")\n",
    "\n",
    "# def predict_image(model, image_path):\n",
    "#     \"\"\"\n",
    "#     Memuat gambar, melakukan preprocessing, dan memprediksinya\n",
    "#     menggunakan model yang dimuat.\n",
    "#     \"\"\"\n",
    "#     img = cv2.imread(image_path)\n",
    "#     if img is None:\n",
    "#         raise ValueError(\"Gambar tidak dapat dibaca.\")\n",
    "    \n",
    "#     img = cv2.resize(img, (64, 64))\n",
    "#     img = img.astype(float) / 255.0\n",
    "#     img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "#     try:\n",
    "#         predictions = run_batch(model, img, training=False)[-1]\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error calling run_batch: {e}\")\n",
    "#         raise Exception(f\"Gagal memprediksi dengan model: {e}\")\n",
    "\n",
    "#     softmax_probabilities = np.exp(predictions) / np.sum(np.exp(predictions))\n",
    "    \n",
    "#     threshold = 0.7\n",
    "#     prediction_index = np.argmax(softmax_probabilities)\n",
    "#     confidence = np.max(softmax_probabilities)\n",
    "    \n",
    "#     labels = ['blight', 'blast', 'tungro', 'healthy']\n",
    "    \n",
    "#     softmax_probabilities = softmax_probabilities.flatten().tolist()\n",
    "    \n",
    "#     if confidence < threshold:\n",
    "#         return 'bukan daun padi', confidence, softmax_probabilities, labels\n",
    "#     else:\n",
    "#         return labels[prediction_index], confidence, softmax_probabilities, labels\n",
    "\n",
    "# def play_sound(prediction):\n",
    "#     \"\"\"Memainkan suara berdasarkan hasil prediksi.\"\"\"\n",
    "#     sounds = {\n",
    "#         \"tungro\": \"sounds/tungro.wav\",\n",
    "#         \"blast\": \"sounds/blast.wav\",\n",
    "#         \"blight\": \"sounds/blight.wav\",\n",
    "#         \"healthy\": \"sounds/healthy.wav\",\n",
    "#         \"bukan daun padi\": \"sounds/not.mp3\"\n",
    "#     }\n",
    "#     sound_file = os.path.join('static', sounds.get(prediction.lower(), \"healthy.wav\"))\n",
    "#     if os.path.exists(sound_file):\n",
    "#         pygame.mixer.music.load(sound_file)\n",
    "#         pygame.mixer.music.play()\n",
    "\n",
    "# @app.route('/predict_api', methods=['POST'])\n",
    "# def predict_api():\n",
    "#     if CNN_loaded is None:\n",
    "#         return jsonify({'error': 'Model belum dimuat. Harap muat model terlebih dahulu.'}), 500\n",
    "\n",
    "#     if 'image' not in request.files:\n",
    "#         return jsonify({'error': 'Tidak ada file gambar yang dipilih.'}), 400\n",
    "\n",
    "#     file = request.files['image']\n",
    "#     if file.filename == '':\n",
    "#         return jsonify({'error': 'Tidak ada file gambar yang dipilih.'}), 400\n",
    "\n",
    "#     try:\n",
    "#         # Buat nama file yang unik untuk menghindari tabrakan\n",
    "#         unique_filename = f\"{uuid.uuid4()}_{secure_filename(file.filename)}\"\n",
    "#         file_path = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)\n",
    "#         file.save(file_path)\n",
    "        \n",
    "#         prediction_label, confidence, probabilities, labels = predict_image(CNN_loaded, file_path)\n",
    "        \n",
    "#         # Tentukan tingkat keparahan berdasarkan label\n",
    "#         if prediction_label == 'healthy':\n",
    "#             severity = 'low'\n",
    "#         elif confidence > 0.95:\n",
    "#             severity = 'high'\n",
    "#         else:\n",
    "#             severity = 'medium'\n",
    "        \n",
    "#         new_result = {\n",
    "#             'id': str(uuid.uuid4()), # ID unik untuk setiap riwayat\n",
    "#             'timestamp': datetime.datetime.now().isoformat(),\n",
    "#             'prediction': prediction_label,\n",
    "#             'confidence': confidence,\n",
    "#             'probabilities': probabilities,\n",
    "#             'labels': labels,\n",
    "#             'image_filename': unique_filename,\n",
    "#             'severity': severity,\n",
    "#         }\n",
    "#         dashboard_data.append(new_result)\n",
    "        \n",
    "#         return jsonify(new_result)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error in prediction: {str(e)}\")\n",
    "#         return jsonify({'error': str(e)}), 500\n",
    "\n",
    "# # -----------------\n",
    "# # API BARU UNTUK RIWAYAT KLASIFIKASI\n",
    "# # -----------------\n",
    "# @app.route('/api/history', methods=['GET'])\n",
    "# def get_history_data():\n",
    "#     history_list = []\n",
    "#     upload_folder = app.config['UPLOAD_FOLDER']\n",
    "    \n",
    "#     # Pesan ini akan muncul sekali setiap kali /api/history dipanggil\n",
    "#     logging.info(\"Mulai memproses permintaan riwayat...\") \n",
    "\n",
    "#     for item in dashboard_data:\n",
    "#         full_image_path = os.path.join(upload_folder, item['image_filename'])\n",
    "        \n",
    "#         # ==========================================================\n",
    "#         # TAMBAHKAN BARIS INI UNTUK MENAMPILKAN PATH DI TERMINAL\n",
    "#         logging.info(f\"Mengecek file di path: {full_image_path}\")\n",
    "#         # ==========================================================\n",
    "\n",
    "#         if os.path.exists(full_image_path):\n",
    "#             logging.info(f\"   -> DITEMUKAN: {item['image_filename']}\") # Tambahan: konfirmasi jika file ada\n",
    "            \n",
    "#             image_url_path = f\"/static/uploads/{item['image_filename']}\"\n",
    "            \n",
    "#             history_list.append({\n",
    "#                 'id': item['id'],\n",
    "#                 'date': datetime.datetime.fromisoformat(item['timestamp']).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "#                 'image': image_url_path,\n",
    "#                 'disease': item['prediction'],\n",
    "#                 'confidence': round(item['confidence'] * 100, 2),\n",
    "#                 'severity': item['severity'],\n",
    "#                 'image_filename': item['image_filename']\n",
    "#             })\n",
    "#         else:\n",
    "#             logging.warning(f\"   -> TIDAK DITEMUKAN: {item['image_filename']}\") # Tambahan: konfirmasi jika file tidak ada\n",
    "\n",
    "#     history_list.sort(key=lambda x: x['date'], reverse=True)\n",
    "#     return jsonify(history_list)\n",
    "\n",
    "# # -----------------\n",
    "# # API BARU UNTUK DASHBOARD\n",
    "# # -----------------\n",
    "# @app.route('/api/dashboard', methods=['GET'])\n",
    "# def get_dashboard_data():\n",
    "#     \"\"\"\n",
    "#     Mengambil data prediksi dari 'database' dan memprosesnya untuk dashboard.\n",
    "#     \"\"\"\n",
    "#     # Buat daftar inisial untuk 12 bulan\n",
    "#     monthly_counts = [{'month': abbr, 'total': 0, 'healthy': 0, 'diseases': 0} for abbr in month_abbr[1:]]\n",
    "    \n",
    "#     # Buat kamus untuk memudahkan pembaruan\n",
    "#     monthly_data_map = {item['month']: item for item in monthly_counts}\n",
    "\n",
    "#     if not dashboard_data:\n",
    "#         return jsonify({\n",
    "#             'total_classifications': 0,\n",
    "#             'classifications_by_month': monthly_counts,\n",
    "#             'classification_distribution': []\n",
    "#         })\n",
    "\n",
    "#     total_classifications = len(dashboard_data)\n",
    "\n",
    "#     # Isi data dari dashboard_data\n",
    "#     for item in dashboard_data:\n",
    "#         month = datetime.datetime.fromisoformat(item['timestamp']).strftime('%b')\n",
    "#         if month in monthly_data_map:\n",
    "#             monthly_data_map[month]['total'] += 1\n",
    "#             if item['prediction'] == 'healthy':\n",
    "#                 monthly_data_map[month]['healthy'] += 1\n",
    "#             else:\n",
    "#                 monthly_data_map[month]['diseases'] += 1\n",
    "    \n",
    "#     # Ubah kembali ke format daftar\n",
    "#     updated_monthly_counts = list(monthly_data_map.values())\n",
    "    \n",
    "#     classification_counts = defaultdict(int)\n",
    "#     for item in dashboard_data:\n",
    "#         classification_counts[item['prediction']] += 1\n",
    "    \n",
    "#     distribution = [{'label': k, 'count': v} for k, v in classification_counts.items()]\n",
    "\n",
    "#     return jsonify({\n",
    "#         'total_classifications': total_classifications,\n",
    "#         'classifications_by_month': updated_monthly_counts,\n",
    "#         'classification_distribution': distribution\n",
    "#     })\n",
    "    \n",
    "# # Tambahkan ini di bagian ENDPOINTS API di file app.ipynb Anda\n",
    "\n",
    "# @app.route('/')\n",
    "# def home():\n",
    "#     \"\"\"Endpoint dasar untuk mengecek status API.\"\"\"\n",
    "#     return jsonify({'status': 'ok', 'message': 'Rice Doctor AI API is running!'})\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(host='0.0.0.0', port=5000, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQLite3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model berhasil dimuat dari: static/models/trained_model_manual_10000002_32_7_resize64_arsitekturbaru.pkl\n",
      "INFO:root:Database berhasil diinisialisasi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.13:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:38] \"GET /api/history HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:38] \"GET /api/history HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:38] \"GET /api/dashboard HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:38] \"GET /api/dashboard HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:44] \"POST /predict_api HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:45] \"GET /api/dashboard HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:45] \"GET /api/dashboard HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:46] \"GET /api/history HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:46] \"GET /api/history HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:46] \"GET /static/uploads/a86e77e1-5ef9-4ccb-b1a0-865318e3ff40_IMG_175.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:48] \"GET /api/dashboard HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:48] \"GET /api/dashboard HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:54:55] \"POST /predict_api HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:55:00] \"POST /predict_api HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:55:01] \"GET /api/dashboard HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:55:01] \"GET /api/dashboard HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:55:03] \"GET /api/history HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:55:03] \"GET /api/history HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:55:03] \"GET /static/uploads/f0f0893d-20ca-482b-9ed5-4f9e716f327e_IMG_20190419_140004.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:55:03] \"GET /static/uploads/566c0368-9f72-479c-8d9a-373ba2ff5902_IMG_20190419_133848.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:55:03] \"\u001b[36mGET /static/uploads/a86e77e1-5ef9-4ccb-b1a0-865318e3ff40_IMG_175.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:55:05] \"GET /api/dashboard HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/Aug/2025 09:55:05] \"GET /api/dashboard HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sqlite3\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from werkzeug.utils import secure_filename\n",
    "import logging\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import uuid\n",
    "from calendar import month_abbr\n",
    "\n",
    "# =========================================================================\n",
    "# Pastikan definisi kelas dan fungsi kustom model Anda (seperti run_batch)\n",
    "# sudah dijalankan di cell notebook sebelum menjalankan cell ini.\n",
    "# =========================================================================\n",
    "\n",
    "# --- Konfigurasi Aplikasi & Database ---\n",
    "app = Flask(__name__, static_folder='static')\n",
    "CORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n",
    "app.config['UPLOAD_FOLDER'] = 'static/uploads'\n",
    "DATABASE = 'history.db' # Nama file database SQLite\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Membuat koneksi ke database SQLite.\"\"\"\n",
    "    conn = sqlite3.connect(DATABASE)\n",
    "    conn.row_factory = sqlite3.Row # Memungkinkan akses kolom berdasarkan nama\n",
    "    return conn\n",
    "\n",
    "def init_db():\n",
    "    \"\"\"Membuat tabel database jika belum ada.\"\"\"\n",
    "    with app.app_context():\n",
    "        conn = get_db_connection()\n",
    "        with open('schema.sql', 'r') as f:\n",
    "            conn.executescript(f.read())\n",
    "        conn.close()\n",
    "        logging.info(\"Database berhasil diinisialisasi.\")\n",
    "\n",
    "# --- Memuat Model Machine Learning ---\n",
    "MODEL_PATH = 'static/models/trained_model_manual_10000002_32_7_resize64_arsitekturbaru.pkl'\n",
    "CNN_loaded = None\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Memuat model dari file pickle.\"\"\"\n",
    "    try:\n",
    "        with open(MODEL_PATH, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "            logging.info(f\"Model berhasil dimuat dari: {MODEL_PATH}\")\n",
    "            return model\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saat memuat model: {e}\")\n",
    "        return None\n",
    "\n",
    "CNN_loaded = load_model()\n",
    "\n",
    "# --- Fungsi Helper untuk Prediksi ---\n",
    "def predict_image(model, image_path):\n",
    "    \"\"\"\n",
    "    Memuat gambar, melakukan preprocessing, dan memprediksinya\n",
    "    menggunakan model yang dimuat.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Gambar tidak dapat dibaca.\")\n",
    "    \n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    img = img.astype(float) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    try:\n",
    "        predictions = run_batch(model, img, training=False)[-1]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error calling run_batch: {e}\")\n",
    "        raise Exception(f\"Gagal memprediksi dengan model: {e}\")\n",
    "\n",
    "    softmax_probabilities = np.exp(predictions) / np.sum(np.exp(predictions))\n",
    "    \n",
    "    threshold = 0.7\n",
    "    prediction_index = np.argmax(softmax_probabilities)\n",
    "    confidence = np.max(softmax_probabilities)\n",
    "    \n",
    "    labels = ['blight', 'blast', 'tungro', 'healthy']\n",
    "    \n",
    "    softmax_probabilities = softmax_probabilities.flatten().tolist()\n",
    "    \n",
    "    if confidence < threshold:\n",
    "        return 'bukan daun padi', confidence, softmax_probabilities, labels\n",
    "    else:\n",
    "        return labels[prediction_index], confidence, softmax_probabilities, labels\n",
    "\n",
    "# --- ENDPOINTS API ---\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    \"\"\"Endpoint dasar untuk mengecek status API.\"\"\"\n",
    "    return jsonify({'status': 'ok', 'message': 'Rice Doctor AI API is running!'})\n",
    "\n",
    "@app.route('/predict_api', methods=['POST'])\n",
    "def predict_api():\n",
    "    \"\"\"Endpoint untuk menerima gambar, memprediksi, dan menyimpan ke DB.\"\"\"\n",
    "    if CNN_loaded is None:\n",
    "        return jsonify({'error': 'Model tidak tersedia di server.'}), 500\n",
    "    if 'image' not in request.files:\n",
    "        return jsonify({'error': 'Tidak ada file gambar yang dikirim.'}), 400\n",
    "\n",
    "    file = request.files['image']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'File gambar tidak valid.'}), 400\n",
    "\n",
    "    try:\n",
    "        unique_filename = f\"{uuid.uuid4()}_{secure_filename(file.filename)}\"\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)\n",
    "        file.save(file_path)\n",
    "        \n",
    "        prediction_label, confidence, probabilities, labels = predict_image(CNN_loaded, file_path)\n",
    "        \n",
    "        if prediction_label in ['healthy', 'bukan daun padi']:\n",
    "            severity = 'low'\n",
    "        elif confidence > 0.95:\n",
    "            severity = 'high'\n",
    "        else:\n",
    "            severity = 'medium'\n",
    "            \n",
    "        # Simpan hasil ke database SQLite\n",
    "        conn = get_db_connection()\n",
    "        item_id = str(uuid.uuid4())\n",
    "        timestamp = datetime.datetime.now().isoformat()\n",
    "        \n",
    "        conn.execute(\n",
    "            'INSERT INTO history (id, timestamp, prediction, confidence, image_filename, severity) VALUES (?, ?, ?, ?, ?, ?)',\n",
    "            (item_id, timestamp, prediction_label, confidence, unique_filename, severity)\n",
    "        )\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "        # Kirim kembali hasil yang baru saja disimpan\n",
    "        return jsonify({\n",
    "            'id': item_id,\n",
    "            'date': datetime.datetime.fromisoformat(timestamp).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'image': f\"/static/uploads/{unique_filename}\",\n",
    "            'prediction': prediction_label, # Ganti 'disease' menjadi 'prediction' agar konsisten\n",
    "            'confidence': confidence,\n",
    "            'severity': severity,\n",
    "            'image_filename': unique_filename,\n",
    "            'probabilities': probabilities, \n",
    "            'labels': labels              \n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saat prediksi: {e}\")\n",
    "        return jsonify({'error': f'Terjadi kesalahan di server: {e}'}), 500\n",
    "\n",
    "@app.route('/api/history', methods=['GET'])\n",
    "def get_history():\n",
    "    \"\"\"Endpoint untuk mendapatkan semua riwayat dari database.\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    # Mengambil semua data dari tabel history, diurutkan dari yang terbaru\n",
    "    history_rows = conn.execute('SELECT * FROM history ORDER BY timestamp DESC').fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    history_list = [dict(row) for row in history_rows]\n",
    "    \n",
    "    # Format data agar sesuai dengan yang diharapkan frontend\n",
    "    formatted_list = [\n",
    "        {\n",
    "            'id': item['id'],\n",
    "            'date': datetime.datetime.fromisoformat(item['timestamp']).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'image': f\"/static/uploads/{item['image_filename']}\",\n",
    "            'disease': item['prediction'],\n",
    "            'confidence': item['confidence'] * 100,\n",
    "            'severity': item['severity'],\n",
    "            'image_filename': item['image_filename']\n",
    "        }\n",
    "        for item in history_list\n",
    "    ]\n",
    "    return jsonify(formatted_list)\n",
    "\n",
    "@app.route('/api/dashboard', methods=['GET'])\n",
    "def get_dashboard_data():\n",
    "    \"\"\"Endpoint untuk data agregat dashboard dari database.\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    # Ambil 'prediction' dan 'timestamp' dari database\n",
    "    rows = conn.execute('SELECT prediction, timestamp FROM history').fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    # Buat daftar inisial untuk 12 bulan\n",
    "    # month_abbr[1:] akan menghasilkan ['Jan', 'Feb', ..., 'Dec']\n",
    "    monthly_counts = [{'month': abbr, 'total': 0, 'healthy': 0, 'diseases': 0} for abbr in month_abbr[1:]]\n",
    "    monthly_data_map = {item['month']: item for item in monthly_counts}\n",
    "\n",
    "    if not rows:\n",
    "        return jsonify({\n",
    "            'total_classifications': 0,\n",
    "            'classifications_by_month': monthly_counts, # Kirim data bulan kosong\n",
    "            'classification_distribution': []\n",
    "        })\n",
    "\n",
    "    # Hitung total dan distribusi\n",
    "    total_classifications = len(rows)\n",
    "    distribution_counts = {}\n",
    "    \n",
    "    # Proses setiap baris data\n",
    "    for row in rows:\n",
    "        prediction = row['prediction']\n",
    "        \n",
    "        # Hitung distribusi\n",
    "        distribution_counts[prediction] = distribution_counts.get(prediction, 0) + 1\n",
    "        \n",
    "        # Hitung data bulanan\n",
    "        month_str = datetime.datetime.fromisoformat(row['timestamp']).strftime('%b') # -> 'Jan', 'Feb', dst.\n",
    "        if month_str in monthly_data_map:\n",
    "            monthly_data_map[month_str]['total'] += 1\n",
    "            if prediction == 'healthy':\n",
    "                monthly_data_map[month_str]['healthy'] += 1\n",
    "            else:\n",
    "                monthly_data_map[month_str]['diseases'] += 1\n",
    "\n",
    "    distribution = [{'label': k, 'count': v} for k, v in distribution_counts.items()]\n",
    "    \n",
    "    # Kirim kembali data lengkap termasuk data bulanan\n",
    "    return jsonify({\n",
    "        'total_classifications': total_classifications,\n",
    "        'classifications_by_month': list(monthly_data_map.values()), # <-- DATA BARU\n",
    "        'classification_distribution': distribution\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Pastikan folder uploads sudah ada\n",
    "    if not os.path.exists(app.config['UPLOAD_FOLDER']):\n",
    "        os.makedirs(app.config['UPLOAD_FOLDER'])\n",
    "    \n",
    "    # Inisialisasi database sebelum menjalankan aplikasi\n",
    "    init_db()\n",
    "    \n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
